[
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "John Curtin’s Stats and Coding Notebook",
    "section": "Welcome",
    "text": "Welcome\nThis web book is a collection of John Curtin’s exploration of stats and coding issues. These chapters are mostly for John and not intended for external use though John may occasionally share it with colleagues to stimulate discussion and debate."
  },
  {
    "objectID": "repeated_measures.html",
    "href": "repeated_measures.html",
    "title": "1  Analysis of Repeated Measures in R",
    "section": "",
    "text": "2 Predicted values and figures\nThis is a demo of predicted values and plot for the model with time as a continuous variable. I use the linear model of time and raw time scores. For the plot, centering doesn’t matter. Its all the same model space and it easier to understand in raw time units. Alternatively, we could use centered time and then change the values on the axis that displays time.\n# we can add the means from raw data to plot and then superimpose the fitted model\nd_plot &lt;- d_long |&gt; \n  group_by(r_time) |&gt; \n  summarize(hdd_mean = mean(hdd), hdd_se = sd(hdd)/ sqrt(length(hdd)))\n\nd_plot &lt;- d_plot |&gt; \n  mutate(hdd_pred = predict(m_raw, newdata = d_plot, re.form = NA)) |&gt; \n  glimpse()\n\nRows: 3\nColumns: 4\n$ r_time   &lt;dbl&gt; 2, 4, 6\n$ hdd_mean &lt;dbl&gt; 36.78182, 25.80000, 26.65152\n$ hdd_se   &lt;dbl&gt; 5.979868, 6.140520, 6.749849\n$ hdd_pred &lt;dbl&gt; 34.80960, 29.74444, 24.67929\n\nd_plot |&gt; \n  ggplot(aes(x = r_time)) +\n    geom_errorbar(aes(ymin = hdd_mean - hdd_se, ymax = hdd_mean + hdd_se),\n                  width = .25) +\n    geom_point(aes(y = hdd_mean)) +\n    geom_line(aes(y = hdd_pred), color = \"red\", linewidth = 1.5) +\n    ylim(0, 50)"
  },
  {
    "objectID": "repeated_measures.html#set-up",
    "href": "repeated_measures.html#set-up",
    "title": "1  Analysis of Repeated Measures in R",
    "section": "1.1 Set up",
    "text": "1.1 Set up\n\n1.1.1 Load packages and data\n\nlibrary(tidyverse)\nlibrary(lme4)\n\n\n\n1.1.2 Read and format data in long format\n\nd_long &lt;- read_csv(\"repeated_measures.csv\", col_types = cols()) |&gt; \n  filter(dyad == \"Patient\") |&gt; \n  select(-dyad) |&gt; \n  filter(time &gt; 0) |&gt; \n  glimpse()\n\nRows: 99\nColumns: 4\n$ study_id &lt;dbl&gt; 600, 600, 600, 101, 101, 101, 102, 102, 102, 100, 100, 100, 1…\n$ arm      &lt;chr&gt; \"PartnerCHESS\", \"PartnerCHESS\", \"PartnerCHESS\", \"A-CHESS\", \"A…\n$ time     &lt;dbl&gt; 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3…\n$ hdd      &lt;dbl&gt; 65.0, 59.5, 42.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 13.6, 1…\n\nd_long |&gt; print(n = 10)\n\n# A tibble: 99 × 4\n   study_id arm           time   hdd\n      &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1      600 PartnerCHESS     1  65  \n 2      600 PartnerCHESS     2  59.5\n 3      600 PartnerCHESS     3  42  \n 4      101 A-CHESS          1 100  \n 5      101 A-CHESS          2 100  \n 6      101 A-CHESS          3 100  \n 7      102 PartnerCHESS     1   0  \n 8      102 PartnerCHESS     2   0  \n 9      102 PartnerCHESS     3   0  \n10      100 PartnerCHESS     1  13.6\n# ℹ 89 more rows\n\n\n\n\n1.1.3 Format data in wide format\n\nd_wide &lt;- d_long |&gt; \n  select(study_id, arm, time, hdd) |&gt; \n  pivot_wider(names_from = time, values_from = hdd) |&gt; \n  rename(time1 = `1`,\n         time2 = `2`, \n         time3 = `3`) |&gt; \n  glimpse()\n\nRows: 33\nColumns: 5\n$ study_id &lt;dbl&gt; 600, 101, 102, 100, 106, 104, 105, 200, 107, 201, 108, 109, 3…\n$ arm      &lt;chr&gt; \"PartnerCHESS\", \"A-CHESS\", \"PartnerCHESS\", \"PartnerCHESS\", \"P…\n$ time1    &lt;dbl&gt; 65.0, 100.0, 0.0, 13.6, 64.4, 100.0, 23.8, 100.0, 4.8, 46.6, …\n$ time2    &lt;dbl&gt; 59.5, 100.0, 0.0, 1.4, 41.9, 0.0, 0.0, 100.0, 0.0, 50.0, 100.…\n$ time3    &lt;dbl&gt; 42.0, 100.0, 0.0, 84.6, 94.4, 0.0, 0.0, 56.1, 0.0, 100.0, 100…\n\nd_wide |&gt; print(n = 10)\n\n# A tibble: 33 × 5\n   study_id arm          time1 time2 time3\n      &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1      600 PartnerCHESS  65    59.5  42  \n 2      101 A-CHESS      100   100   100  \n 3      102 PartnerCHESS   0     0     0  \n 4      100 PartnerCHESS  13.6   1.4  84.6\n 5      106 PartnerCHESS  64.4  41.9  94.4\n 6      104 A-CHESS      100     0     0  \n 7      105 PartnerCHESS  23.8   0     0  \n 8      200 PartnerCHESS 100   100    56.1\n 9      107 A-CHESS        4.8   0     0  \n10      201 A-CHESS       46.6  50   100  \n# ℹ 23 more rows\n\n\n\n\n1.1.4 Setting contrast matrices for factors\n\nsee: https://marissabarlaz.github.io/portfolio/contrastcoding/\nDefault for unordered factors is treatment/dummy\nWe typically want centered orthogonal, and unit weighted. Helmert often good choice\nBelow, we demo how to set up contrast matrices by code\nWe will apply them later as needed\nWe make Helmert contrast matrices for 2 and 3 level factors here\n\n\n(helmert2 = matrix(c(-.5, .5), ncol = 1, dimnames = list(c(\"time1\", \"time2\"), c(\"t2v1\"))))\n\n      t2v1\ntime1 -0.5\ntime2  0.5\n\n(helmert3 = matrix(c(-2/3, 1/3, 1/3, 0, -.5, .5), ncol = 2, dimnames = list(c(\"time1\", \"time2\", \"time3\"), c(\"t32v1\", \"t3v2\"))))\n\n           t32v1 t3v2\ntime1 -0.6666667  0.0\ntime2  0.3333333 -0.5\ntime3  0.3333333  0.5"
  },
  {
    "objectID": "repeated_measures.html#explore-two-level-repeated-measures",
    "href": "repeated_measures.html#explore-two-level-repeated-measures",
    "title": "1  Analysis of Repeated Measures in R",
    "section": "1.2 Explore two level repeated measures",
    "text": "1.2 Explore two level repeated measures\n\nUse only time 1 and time 2 to demo two level repeated measures analyses\n\n\nd2_long &lt;- d_long |&gt; \n  filter(time &lt; 3) |&gt; \n  glimpse()\n\nRows: 66\nColumns: 4\n$ study_id &lt;dbl&gt; 600, 600, 101, 101, 102, 102, 100, 100, 106, 106, 104, 104, 1…\n$ arm      &lt;chr&gt; \"PartnerCHESS\", \"PartnerCHESS\", \"A-CHESS\", \"A-CHESS\", \"Partne…\n$ time     &lt;dbl&gt; 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1…\n$ hdd      &lt;dbl&gt; 65.0, 59.5, 100.0, 100.0, 0.0, 0.0, 13.6, 1.4, 64.4, 41.9, 10…\n\nd2_wide &lt;- d_wide |&gt; \n  select(-time3) |&gt; \n  glimpse()\n\nRows: 33\nColumns: 4\n$ study_id &lt;dbl&gt; 600, 101, 102, 100, 106, 104, 105, 200, 107, 201, 108, 109, 3…\n$ arm      &lt;chr&gt; \"PartnerCHESS\", \"A-CHESS\", \"PartnerCHESS\", \"PartnerCHESS\", \"P…\n$ time1    &lt;dbl&gt; 65.0, 100.0, 0.0, 13.6, 64.4, 100.0, 23.8, 100.0, 4.8, 46.6, …\n$ time2    &lt;dbl&gt; 59.5, 100.0, 0.0, 1.4, 41.9, 0.0, 0.0, 100.0, 0.0, 50.0, 100.…\n\n\n\n1.2.1 diff score approach\nThis is the standard/traditional way to analyse this design and the benchmark for comparison\n\nTime effect tested using difference score for time2 - time1\nExplicitly calculate that difference score in df\nNo assumption of sphericity is needed\n\nThis is the test of the two level Time variable\n\nd_wide |&gt; \n  mutate(diff = time2 - time1) |&gt; \n  lm(diff ~ 1, data = _) |&gt; \n  summary()\n\n\nCall:\nlm(formula = diff ~ 1, data = mutate(d_wide, diff = time2 - time1))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-89.018 -11.518   6.182  10.982  34.582 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  -10.982      3.984  -2.756  0.00958 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 22.89 on 32 degrees of freedom\n\n\nIf you wanted to test the intercept in the between subject model you could do this. Not really useful here, but can be informative in some situations and also used when we have between subject variables in the design.\n\nd_wide |&gt; \n  mutate(ave = (time2 + time1) / 2) |&gt; \n  lm(ave ~ 1, data = _) |&gt; \n  summary()\n\n\nCall:\nlm(formula = ave ~ 1, data = mutate(d_wide, ave = (time2 + time1)/2))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-31.291 -28.741  -8.791  17.009  68.709 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   31.291      5.724   5.467 5.11e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 32.88 on 32 degrees of freedom\n\n\n\n\n1.2.2 lmer approach with time as manually coded regressor\n\nThis is first option using manually coded regressor for time (time_2v1, 0.5 vs. -0.5)\nUse random intercept but no random slope for time when there are no psuedoreplications (i.e., where there is only one observation per cell). It is not possible to calculate both a by-subject random slope AND a by-subject random intercept for Time for each subject when there are only two observations for Time (i.e., this “two parameter” model would perfectly fit the two observations available for each subject!)\nUse Anova() from car package on lmer object to get p-values\n\nFirst code the regressor for the time contrast\n\nd2_long &lt;- d2_long |&gt; \n  mutate(time_2v1 = if_else(time == 1, -.5, .5)) |&gt;\n  glimpse()\n\nRows: 66\nColumns: 5\n$ study_id &lt;dbl&gt; 600, 600, 101, 101, 102, 102, 100, 100, 106, 106, 104, 104, 1…\n$ arm      &lt;chr&gt; \"PartnerCHESS\", \"PartnerCHESS\", \"A-CHESS\", \"A-CHESS\", \"Partne…\n$ time     &lt;dbl&gt; 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1…\n$ hdd      &lt;dbl&gt; 65.0, 59.5, 100.0, 100.0, 0.0, 0.0, 13.6, 1.4, 64.4, 41.9, 10…\n$ time_2v1 &lt;dbl&gt; -0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5, …\n\nd2_long |&gt; print(n = 10)\n\n# A tibble: 66 × 5\n   study_id arm           time   hdd time_2v1\n      &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1      600 PartnerCHESS     1  65       -0.5\n 2      600 PartnerCHESS     2  59.5      0.5\n 3      101 A-CHESS          1 100       -0.5\n 4      101 A-CHESS          2 100        0.5\n 5      102 PartnerCHESS     1   0       -0.5\n 6      102 PartnerCHESS     2   0        0.5\n 7      100 PartnerCHESS     1  13.6     -0.5\n 8      100 PartnerCHESS     2   1.4      0.5\n 9      106 PartnerCHESS     1  64.4     -0.5\n10      106 PartnerCHESS     2  41.9      0.5\n# ℹ 56 more rows\n\n\nThen do analysis.\n\nDo NOT use by subject random slope for time as noted above\nBoth parameter estimates (time and intercept) match above\np value for time and intercept match traditional diff score analysis\n\n\nm2a &lt;- d2_long |&gt; \n  lmer(hdd ~ time_2v1 + (1 | study_id), data = _)\n\nm2a\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: hdd ~ time_2v1 + (1 | study_id)\n   Data: d2_long\nREML criterion at convergence: 612.5259\nRandom effects:\n Groups   Name        Std.Dev.\n study_id (Intercept) 30.83   \n Residual             16.19   \nNumber of obs: 66, groups:  study_id, 33\nFixed Effects:\n(Intercept)     time_2v1  \n      31.29       -10.98  \n\nm2a |&gt; \n  car::Anova(type = 3, test = \"F\")\n\nAnalysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)\n\nResponse: hdd\n                  F Df Df.res    Pr(&gt;F)    \n(Intercept) 29.8846  1     32 5.109e-06 ***\ntime_2v1     7.5963  1     32  0.009575 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n1.2.3 lmer approach with time as factor\n\nCode time as a factor\n\n\nd2_long &lt;- d2_long |&gt; \n  mutate(time = factor(time, labels = c(\"time1\", \"time2\")))\n\n\nDefault contrasts for Time were treatment/dummy\nWe will apply centered (helmert) contrast matrix from earlier\n\n\ncontrasts(d2_long$time)\n\n      time2\ntime1     0\ntime2     1\n\ncontrasts(d2_long$time) &lt;- helmert2\ncontrasts(d2_long$time)\n\n      t2v1\ntime1 -0.5\ntime2  0.5\n\n\n\nDo NOT use by subject random slope for time as described earlier\nParemeter estimates and p-values match\n\n\nm2b &lt;- d2_long |&gt; \n  lmer(hdd ~ time + (1 | study_id), data = _)\n\nm2b\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: hdd ~ time + (1 | study_id)\n   Data: d2_long\nREML criterion at convergence: 612.5259\nRandom effects:\n Groups   Name        Std.Dev.\n study_id (Intercept) 30.83   \n Residual             16.19   \nNumber of obs: 66, groups:  study_id, 33\nFixed Effects:\n(Intercept)     timet2v1  \n      31.29       -10.98  \n\nm2b |&gt; \n  car::Anova(type = 3, test = \"F\")\n\nAnalysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)\n\nResponse: hdd\n                  F Df Df.res    Pr(&gt;F)    \n(Intercept) 29.8846  1     32 5.109e-06 ***\ntime         7.5963  1     32  0.009575 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n1.2.4 lmer approach with by-subject random effect of time\n\nNOPE!\n! number of observations (=66) &lt;= number of random effects (=66) for term (1 + c_time | study_id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable\nThis WOULD be correct if we had psudeoreplications\nThis is because you cant estimate both a random intercept and a random slope for time with only two observations. The analogy would be fitting a two parameter model when N=2. Model would perfectly fit the data!\nThis is true regardless if you use time as factor or regressor. Those are equivalent analyses.\n\n\nd2_long |&gt; \n  lmer(hdd ~ time + (1 + time | study_id), data = _) |&gt; \n  car::Anova(type = 3, test = \"F\")\n\nYou could try to force it\n\nignore check of nobs vs nRe\nIn checkConv(attr(opt, “derivs”), opt\\(par, ctrl = control\\)checkConv, :Model is nearly unidentifiable: large eigenvalue ratio - Rescale variables?\nIt does yield the same solution as earlier models but with the above warning\n\n\nm2c &lt;- d2_long |&gt; \n  lmer(hdd ~ time + (1 + time | study_id), data = _,\n       control = lmerControl(check.nobs.vs.nRE = \"ignore\"))\n\nm2c\n\nm2c |&gt; \n  car::Anova(type = 3, test = \"F\")"
  },
  {
    "objectID": "repeated_measures.html#explore-three-level-repeated-measures",
    "href": "repeated_measures.html#explore-three-level-repeated-measures",
    "title": "1  Analysis of Repeated Measures in R",
    "section": "1.3 Explore three level repeated measures",
    "text": "1.3 Explore three level repeated measures\n\n1.3.1 Using afex::aov_car\naov_car() from afex supports traditional anova designs in R. see also aov()\n\nRemember that with 3 level repeated measures variables we now need to make an assumption of sphericity\nThis means that the variance of all the difference scores (e.g. time1 - time2, time1-time3, time2-time3) are equal\nThis assumption is similar to the assumption about equal variances across groups in between subject anovas. These assumptiosn allow each model to pool variances across groups (between subjects) or difference scores (within subject) to test the omnibus (in this case 2df) main effect. Remember that the error term for a 1 df within subject test is the variance of the difference. For 2df test, we need to pool two of these differences, which is only appropriate if those variances are the same.\nCompound symetry is a stricter form of sphericity (var1 + var2 + covar12 = k for all combos of variates) but its often needed to have sphericity assumption met.\nMachley test for sphericity exists but it is a poor test. Underpowered for small N, overpowered for large N.\nIf sphericity is violated, you can do df correction (GG or HF)\n\nFirst we need to set up 3-level time as a factor with helmert contrasts using the long format data\n\nd_long &lt;- d_long |&gt; \n  mutate(time = factor(time, labels = c(\"time1\", \"time2\", \"time3\")))\n\ncontrasts(d_long$time)\n\n      time2 time3\ntime1     0     0\ntime2     1     0\ntime3     0     1\n\ncontrasts(d_long$time) &lt;- helmert3\ncontrasts(d_long$time)\n\n           t32v1 t3v2\ntime1 -0.6666667  0.0\ntime2  0.3333333 -0.5\ntime3  0.3333333  0.5\n\n\naov_car() provides us with main effect of Time (2 df) with the pooled error term (64 ddf).\n\nAs noted above, this is only appropriate if sphericity assumption is met.\n\n\nm_afex &lt;- d_long |&gt; \n  afex::aov_car(hdd ~ time + Error(study_id/time), data = _)\n\nsummary(m_afex)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n            Sum Sq num Df Error SS den Df F value    Pr(&gt;F)    \n(Intercept)  87588      1   104463     32 26.8308 1.178e-05 ***\ntime          2463      2    21227     64  3.7136   0.02979 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nMauchly Tests for Sphericity\n\n     Test statistic  p-value\ntime        0.84158 0.069025\n\n\nGreenhouse-Geisser and Huynh-Feldt Corrections\n for Departure from Sphericity\n\n      GG eps Pr(&gt;F[GG])  \ntime 0.86325     0.0366 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n        HF eps Pr(&gt;F[HF])\ntime 0.9079611 0.03422039\n\n\n\nCan get corrections to dfs if assumption is violated. Use anova() from stats package\n\n\nanova(m_afex, correction = \"none\")\n\nAnova Table (Type 3 tests)\n\nResponse: hdd\n     num Df den Df    MSE      F      ges  Pr(&gt;F)  \ntime      2     64 331.68 3.7136 0.019222 0.02979 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(m_afex, correction = \"GG\")\n\nAnova Table (Type 3 tests)\n\nResponse: hdd\n     num Df den Df    MSE      F      ges Pr(&gt;F)  \ntime 1.7265 55.248 384.22 3.7136 0.019222 0.0366 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(m_afex, correction = \"HF\")\n\nAnova Table (Type 3 tests)\n\nResponse: hdd\n     num Df den Df   MSE      F      ges  Pr(&gt;F)  \ntime 1.8159  58.11 365.3 3.7136 0.019222 0.03422 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe can use emmeans package to get cell means and 1 df contrasts\n\nnote the formula for the mean contrasts it NOT the helmert coefficients, but the actual algebraic formula for the contrasts we want.\nThis ALSO gives use tests of contrasts with SEPARATE, not POOLED error (note ddf = 32)\nWe want separate error because no assumption of sphericity needed\nI have not seen pooled contrasts reported though they make sense to me as an option IF pooling is appropriate given sphericity\n\n\n(means &lt;- emmeans::emmeans(m_afex, ~ time))\n\n time  emmean   SE df lower.CL upper.CL\n time1   36.8 5.98 32     24.6     49.0\n time2   25.8 6.14 32     13.3     38.3\n time3   26.7 6.75 32     12.9     40.4\n\nConfidence level used: 0.95 \n\nemmeans::contrast(means, list(t32v1 = c(-1, .5, .5), t3v2 = c(0,-1,1))) \n\n contrast estimate   SE df t.ratio p.value\n t32v1     -10.556 4.23 32  -2.495  0.0180\n t3v2        0.852 4.04 32   0.211  0.8344\n\n\n\n\n1.3.2 Diff score approach\nFirst here are the time contrast models.\n\nCRITICALLY, this tests contrasts with SEPARATE (rather than pooled) error. Note ddf = 32 for contrasts\nThis matches contrasts from aov_car()\nThis method does not provide test of main effect of time (2 df)\n\n\nd_wide |&gt; \n  mutate(diff_23v1 = (time2 + time3) / 2 - time1) |&gt; \n  lm(diff_23v1 ~ 1, data = _) |&gt; \n  summary()\n\n\nCall:\nlm(formula = diff_23v1 ~ 1, data = mutate(d_wide, diff_23v1 = (time2 + \n    time3)/2 - time1))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-89.444 -11.394   7.206  10.556  39.956 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  -10.556      4.231  -2.495    0.018 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 24.31 on 32 degrees of freedom\n\nd_wide |&gt;\n  mutate(diff_3v2 = time3 - time2) |&gt; \n  lm(diff_3v2 ~ 1, data = _) |&gt; \n  summary()\n\n\nCall:\nlm(formula = diff_3v2 ~ 1, data = mutate(d_wide, diff_3v2 = time3 - \n    time2))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-44.752  -3.452  -0.852  -0.852  82.348 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   0.8515     4.0411   0.211    0.834\n\nResidual standard error: 23.21 on 32 degrees of freedom\n\n\nAnd here is the main effects model for the intercept for time\n\nd_wide |&gt; \n  mutate(ave = (time1 + time2 + time3) / 3) |&gt; \n  lm(ave ~ 1, data = _) |&gt; \n  summary()\n\n\nCall:\nlm(formula = ave ~ 1, data = mutate(d_wide, ave = (time1 + time2 + \n    time3)/3))\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-29.74 -28.04 -11.31  10.66  70.26 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   29.744      5.742    5.18 1.18e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 32.99 on 32 degrees of freedom\n\n\n\n\n1.3.3 lmer approach with time as factor\n\nWe do NOT include by subject random slope for time because there are no pseudoreplications. Once again, estimating 3 parameters (random intercept and two random slopes) will perfectly fit the 3 observations per subject\nGets 2df main effect but NOT contrasts\nMatches main effect results from aov_car() when sphericity is assumed.\nThis makes some sense too. If you dont allow for random slopes, then all the subjects have the SAME difference scores for the two contrasts and therefore 0 variance. Thus the variance of both are the same and we are just left with variance in intercept and residual within subject.\nThis solution is not appropriate if sphericity is not met\nAnd you would need to got to aov_car() or similar to test for sphericity and get corrections if needed. NOT A GOOD SOLUTION IMHO\n\n\nm3a&lt;- d_long |&gt; \n  lmer(hdd ~ time + (1 | study_id), data = _)\n\nm3a\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: hdd ~ time + (1 | study_id)\n   Data: d_long\nREML criterion at convergence: 913.2997\nRandom effects:\n Groups   Name        Std.Dev.\n study_id (Intercept) 31.27   \n Residual             18.21   \nNumber of obs: 99, groups:  study_id, 33\nFixed Effects:\n(Intercept)    timet32v1     timet3v2  \n    29.7444     -10.5561       0.8515  \n\nm3a |&gt; car::Anova(type = 3, test = \"F\")\n\nAnalysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)\n\nResponse: hdd\n                  F Df Df.res    Pr(&gt;F)    \n(Intercept) 26.8308  1     32 1.178e-05 ***\ntime         3.7136  2     64   0.02979 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n1.3.4 lmer approach with regressors for time\n\nDo NOT include by subject random slope for time because no pseudoreplications\nGets 1 df contrasts for time and parameter estimates match\nBUT uses a pooled error to test contrasts. ddf = 64. So p-values do NOT match. Appropriate (better?) if sphericity holds but definitely not if it doesn’t!\nDoes not get main effect (2df) for time\n\nFirst, add regressors for helmert contrasts for three level time variable\n\nd_long &lt;- d_long |&gt; \n  mutate(time_32v1 = case_match(time,\n                                \"time1\" ~ -2/3,\n                                c(\"time2\", \"time3\") ~ 1/3),\n         time_3v2 = case_match(time, \n                               \"time1\" ~ 0,\n                               \"time2\" ~ -.5,\n                               \"time3\" ~ .5))\n\nd_long |&gt; print(n = 10)\n\n# A tibble: 99 × 6\n   study_id arm          time    hdd time_32v1 time_3v2\n      &lt;dbl&gt; &lt;chr&gt;        &lt;fct&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1      600 PartnerCHESS time1  65      -0.667      0  \n 2      600 PartnerCHESS time2  59.5     0.333     -0.5\n 3      600 PartnerCHESS time3  42       0.333      0.5\n 4      101 A-CHESS      time1 100      -0.667      0  \n 5      101 A-CHESS      time2 100       0.333     -0.5\n 6      101 A-CHESS      time3 100       0.333      0.5\n 7      102 PartnerCHESS time1   0      -0.667      0  \n 8      102 PartnerCHESS time2   0       0.333     -0.5\n 9      102 PartnerCHESS time3   0       0.333      0.5\n10      100 PartnerCHESS time1  13.6    -0.667      0  \n# ℹ 89 more rows\n\n\n\nm3b &lt;- d_long |&gt; \n  lme4::lmer(hdd ~ time_32v1 + time_3v2 + (1 | study_id), data = _)\n\nm3b\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: hdd ~ time_32v1 + time_3v2 + (1 | study_id)\n   Data: d_long\nREML criterion at convergence: 913.2997\nRandom effects:\n Groups   Name        Std.Dev.\n study_id (Intercept) 31.27   \n Residual             18.21   \nNumber of obs: 99, groups:  study_id, 33\nFixed Effects:\n(Intercept)    time_32v1     time_3v2  \n    29.7444     -10.5561       0.8515  \n\nm3b |&gt; \n  car::Anova(type = 3, test = \"F\")\n\nAnalysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)\n\nResponse: hdd\n                  F Df Df.res    Pr(&gt;F)    \n(Intercept) 26.8308  1     32 1.178e-05 ***\ntime_32v1    7.3911  1     64  0.008426 ** \ntime_3v2     0.0361  1     64  0.849971    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n1.3.5 lmer approach with regressors for time AND separate error terms\nI don’t show code for this but we could aggregate down to long format but just the two levels (with two rows per subject) of time separately for each time contrast and then we would be back to the 2 level lmer approach to time from above. This would be fine but its cumbersome so I don’t think this is worth it.\n\n\n1.3.6 With random effect for time\n\nNOPE\n! number of observations (=99) &lt;= number of random effects (=99) for term (1 + time | study_id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable\nAgain, no pseudoreplications so no by-subject random effect for time can be estimated\n\n\nm3c &lt;- d_long |&gt; \n  lmer(hdd ~ time + (1 + time | study_id), data = _)\n\nAnd if we force it, we get warnings… * 1: In checkConv(attr(opt, “derivs”), opt$par, ctrl = control\\(checkConv, :  unable to evaluate scaled gradient * In checkConv(attr(opt, \"derivs\"), opt\\)par, ctrl = control$checkConv, : Model failed to converge: degenerate Hessian with 1 negative eigenvalues\n\nm3c &lt;- d_long |&gt; \n  lmer(hdd ~ time + (1 + time | study_id), data = _,\n       control = lmerControl(check.nobs.vs.nRE = \"ignore\",\n                             optCtrl = list(maxfun = 1000000)))\n\n\n\n1.3.7 lmer with time as continuous variable\nNow we can specify by subject random slope for time\nAnd this model doesn’t make sphericity assumption because it allows for the slopes to vary by subject\n\nd_long &lt;- d_long |&gt; \n  mutate(r_time = as.numeric(time) * 2,  # for 2, 4, and 6 months\n         c_time = r_time - 2) |&gt; \n  glimpse()\n\nRows: 99\nColumns: 8\n$ study_id  &lt;dbl&gt; 600, 600, 600, 101, 101, 101, 102, 102, 102, 100, 100, 100, …\n$ arm       &lt;chr&gt; \"PartnerCHESS\", \"PartnerCHESS\", \"PartnerCHESS\", \"A-CHESS\", \"…\n$ time      &lt;fct&gt; time1, time2, time3, time1, time2, time3, time1, time2, time…\n$ hdd       &lt;dbl&gt; 65.0, 59.5, 42.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 13.6, …\n$ time_32v1 &lt;dbl&gt; -0.6666667, 0.3333333, 0.3333333, -0.6666667, 0.3333333, 0.3…\n$ time_3v2  &lt;dbl&gt; 0.0, -0.5, 0.5, 0.0, -0.5, 0.5, 0.0, -0.5, 0.5, 0.0, -0.5, 0…\n$ r_time    &lt;dbl&gt; 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, …\n$ c_time    &lt;dbl&gt; 0, 2, 4, 0, 2, 4, 0, 2, 4, 0, 2, 4, 0, 2, 4, 0, 2, 4, 0, 2, …\n\n\n\nm_raw &lt;- d_long |&gt; \n  lmer(hdd ~ r_time + (1 + r_time | study_id), data = _)\n\nm_raw\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: hdd ~ r_time + (1 + r_time | study_id)\n   Data: d_long\nREML criterion at convergence: 917.5282\nRandom effects:\n Groups   Name        Std.Dev. Corr \n study_id (Intercept) 34.504        \n          r_time       5.552   -0.44\n Residual             14.732        \nNumber of obs: 99, groups:  study_id, 33\nFixed Effects:\n(Intercept)       r_time  \n     39.875       -2.533  \n\nm_raw |&gt; \n  car::Anova(type = 3, test = \"F\")\n\nAnalysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)\n\nResponse: hdd\n                  F Df Df.res    Pr(&gt;F)    \n(Intercept) 30.9206  1     32 3.887e-06 ***\nr_time       3.6522  1     32   0.06499 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCentering matters - here only for intercept but more impacts with higher order models\n\nm_center &lt;- d_long |&gt; \n  lmer(hdd ~ c_time + (1 + c_time | study_id), data = _)\n\nm_center\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: hdd ~ c_time + (1 + c_time | study_id)\n   Data: d_long\nREML criterion at convergence: 917.5282\nRandom effects:\n Groups   Name        Std.Dev. Corr \n study_id (Intercept) 31.303        \n          c_time       5.552   -0.13\n Residual             14.732        \nNumber of obs: 99, groups:  study_id, 33\nFixed Effects:\n(Intercept)       c_time  \n     34.810       -2.533  \n\nm_center |&gt; \n  car::Anova(type = 3, test = \"F\")\n\nAnalysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)\n\nResponse: hdd\n                  F Df Df.res    Pr(&gt;F)    \n(Intercept) 34.4489  1     32 1.585e-06 ***\nc_time       3.6523  1     32   0.06498 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTo fit poly model, you probably want to use centered time because linear effect will be at time = 0 (time mid point). Or chose another sensible 0 point.\n\nd_long &lt;- d_long |&gt; \n  mutate(c_time2 = c_time^2) |&gt; \n  glimpse()\n\nRows: 99\nColumns: 9\n$ study_id  &lt;dbl&gt; 600, 600, 600, 101, 101, 101, 102, 102, 102, 100, 100, 100, …\n$ arm       &lt;chr&gt; \"PartnerCHESS\", \"PartnerCHESS\", \"PartnerCHESS\", \"A-CHESS\", \"…\n$ time      &lt;fct&gt; time1, time2, time3, time1, time2, time3, time1, time2, time…\n$ hdd       &lt;dbl&gt; 65.0, 59.5, 42.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 13.6, …\n$ time_32v1 &lt;dbl&gt; -0.6666667, 0.3333333, 0.3333333, -0.6666667, 0.3333333, 0.3…\n$ time_3v2  &lt;dbl&gt; 0.0, -0.5, 0.5, 0.0, -0.5, 0.5, 0.0, -0.5, 0.5, 0.0, -0.5, 0…\n$ r_time    &lt;dbl&gt; 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, …\n$ c_time    &lt;dbl&gt; 0, 2, 4, 0, 2, 4, 0, 2, 4, 0, 2, 4, 0, 2, 4, 0, 2, 4, 0, 2, …\n$ c_time2   &lt;dbl&gt; 0, 4, 16, 0, 4, 16, 0, 4, 16, 0, 4, 16, 0, 4, 16, 0, 4, 16, …\n\n\nBut you can’t fit poly model with quadratic effect with random slopes because, once again cant estimate intercept and both random slopes without more observations per subject\nError: number of observations (=99) &lt;= number of random effects (=99) for term (1 + c_time + c_time2 | study_id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable\n\nm_poly &lt;- d_long |&gt; \n  lmer(hdd ~ c_time + c_time2 + (1 + c_time + c_time2 | study_id), data = _)\n\nBut you CAN return to not estimating by subject random slopes. I suspect that this has the same sphericity issue though! Not sure about that but it seems to make sense that you are putting an unrealisitc (or at least unevaluated) assumption on the strucure of the error.\n\nm_poly &lt;- d_long |&gt; \n  lmer(hdd ~ c_time + c_time2 + (1 | study_id), data = _)\n\nm_poly\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: hdd ~ c_time + c_time2 + (1 | study_id)\n   Data: d_long\nREML criterion at convergence: 918.8449\nRandom effects:\n Groups   Name        Std.Dev.\n study_id (Intercept) 31.27   \n Residual             18.21   \nNumber of obs: 99, groups:  study_id, 33\nFixed Effects:\n(Intercept)       c_time      c_time2  \n     36.782       -8.449        1.479  \n\nm_poly |&gt; \n  car::Anova(type = 3, test = \"F\")\n\nAnalysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)\n\nResponse: hdd\n                 F Df Df.res    Pr(&gt;F)    \n(Intercept) 34.099  1 45.389 5.255e-07 ***\nc_time       4.371  1 64.000   0.04053 *  \nc_time2      2.322  1 64.000   0.13248    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "bayes.html#set-up-packages-and-fake-data",
    "href": "bayes.html#set-up-packages-and-fake-data",
    "title": "2  Bayesian Analyses with rstanarm",
    "section": "2.1 Set up packages and fake data",
    "text": "2.1 Set up packages and fake data\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tidyposterior)\nlibrary(rstanarm)\n\nMake fake data\n\nset.seed(123456)\nauc &lt;- tibble(repeat_id = rep(1:3, each = 10),\n              fold_id = rep(1:10, times = 3),\n              auc_1 = rnorm(30, .90, .01),\n              auc_2 = rnorm(30, .85, .01),\n              auc_3 = rnorm(30, .85, .01)) |&gt; print()\n\n# A tibble: 30 × 5\n   repeat_id fold_id auc_1 auc_2 auc_3\n       &lt;int&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1         1       1 0.908 0.841 0.844\n 2         1       2 0.897 0.851 0.853\n 3         1       3 0.896 0.840 0.851\n 4         1       4 0.901 0.823 0.842\n 5         1       5 0.923 0.839 0.856\n 6         1       6 0.908 0.841 0.848\n 7         1       7 0.913 0.866 0.848\n 8         1       8 0.925 0.860 0.850\n 9         1       9 0.912 0.860 0.845\n10         1      10 0.896 0.839 0.843\n# ℹ 20 more rows"
  },
  {
    "objectID": "bayes.html#background-reading",
    "href": "bayes.html#background-reading",
    "title": "2  Bayesian Analyses with rstanarm",
    "section": "2.2 Background reading",
    "text": "2.2 Background reading\n\nRead help for perf_mod()\nRead help for stan_glmer()\nhttps://www.tmwr.org/compare\nhttps://mc-stan.org/users/documentation/\nhttps://mc-stan.org/rstanarm/articles/\n\nhttps://mc-stan.org/rstanarm/articles/rstanarm.html\nhttps://mc-stan.org/rstanarm/articles/priors.html\nhttps://mc-stan.org/rstanarm/articles/continuous.html\nhttps://www.andrewheiss.com/blog/2022/09/26/guide-visualizing-types-posteriors/"
  },
  {
    "objectID": "bayes.html#tidymodels-approach",
    "href": "bayes.html#tidymodels-approach",
    "title": "2  Bayesian Analyses with rstanarm",
    "section": "2.3 Tidymodels approach",
    "text": "2.3 Tidymodels approach\nUses perf_mod() from tidyposterior\n\nTwo random intercept terms are used; one for the repeat and another for the fold within repeat. These also have exchangeable correlation structures.\nWhen the argument hetero_var = TRUE, the variance structure uses random intercepts for each model term. Use this formula too? statistic ~ model + (model + 0| id2/id)\nNotice dials and knobs to consider in comments\n\n\nset.seed(101)\npp &lt;- auc |&gt; \n  rename(id = repeat_id,\n         id2 = fold_id) |&gt; \n  perf_mod(formula = statistic ~ model + (1 | id2/id),\n         # prior_intercept = rstanarm::student_t(autoscale = TRUE),\n         # prior = rstanarm::student_t(autoscale = TRUE),\n         # hetero_var = TRUE,\n         # transform = tidyposterior::logit_trans,  # for skewed & bounded AUC\n         iter = 2000, chains = 4, # defaults listed here for easy increase  \n         adapt_delta = .80,   # default = .80.  Increase to &lt; 1\n         # cores = 4, seed = 12345,\n         family = gaussian, \n)  \n\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 4.6e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.46 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 5.023 seconds (Warm-up)\nChain 1:                0.324 seconds (Sampling)\nChain 1:                5.347 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.7e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 4.466 seconds (Warm-up)\nChain 2:                0.39 seconds (Sampling)\nChain 2:                4.856 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1.7e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 4.801 seconds (Warm-up)\nChain 3:                0.293 seconds (Sampling)\nChain 3:                5.094 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 3.2e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 5.061 seconds (Warm-up)\nChain 4:                0.395 seconds (Sampling)\nChain 4:                5.456 seconds (Total)\nChain 4: \n\n\nModel coefficients\n\npp$stan |&gt; summary(pars = c(\"modelauc_2\", \"modelauc_3\"),\n        probs = c(0.025, 0.975),\n        digits = 2) \n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      statistic ~ model + (1 | id2/id)\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 90\n groups:       id:id2 (30), id2 (10)\n\nEstimates:\n             mean   sd    2.5%   97.5%\nmodelauc_2 -0.06   0.00 -0.06  -0.05  \nmodelauc_3 -0.06   0.00 -0.06  -0.05  \n\nMCMC diagnostics\n           mcse Rhat n_eff\nmodelauc_2 0.00 1.00 4860 \nmodelauc_3 0.00 1.00 4400 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\n\nTo get info on priors selected\n\nrstanarm::prior_summary(pp$stan)\n\nPriors for model 'pp$stan' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 0.87, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 0.87, scale = 0.071)\n\nCoefficients\n  Specified prior:\n    ~ normal(location = [0,0], scale = [2.5,2.5])\n  Adjusted prior:\n    ~ normal(location = [0,0], scale = [0.15,0.15])\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 35)\n\nCovariance\n ~ decov(reg. = 1, conc. = 1, shape = 1, scale = 1)\n------\nSee help('prior_summary.stanreg') for more details\n\n\nFor diagnostics\n\n# shinystan::launch_shinystan(pp$stan)\n\nCIs for each model\n\npp_tidy &lt;- pp %&gt;% \n  tidy(seed = 123)\n\nq = c(.025, .5, .975)\npp_tidy %&gt;% \n  group_by(model) %&gt;% \n  summarize(mean = mean(posterior),\n            median = quantile(posterior, probs = q[2]),\n            lower = quantile(posterior, probs = q[1]), \n            upper = quantile(posterior, probs = q[3])) |&gt; \n  mutate(model = factor(model, levels = c(\"auc_1\", \"auc_2\", \"auc_3\"))) |&gt; \n  arrange(model)\n\n# A tibble: 3 × 5\n  model  mean median lower upper\n  &lt;fct&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 auc_1 0.904  0.904 0.900 0.908\n2 auc_2 0.847  0.847 0.843 0.851\n3 auc_3 0.848  0.848 0.844 0.852\n\n\nModel contrasts\n\npp_contrasts &lt;- contrast_models(pp, \n                                list(\"auc_1\",\"auc_1\", \"auc_2\"), \n                                list(\"auc_2\", \"auc_3\", \"auc_3\"))\n\nDo contrasts with ROPE\n\nuse +- .01 for ROPE\n95% CI\n\n\nsummary(pp_contrasts, size = .01, prob = 0.95)\n\n# A tibble: 3 × 9\n  contrast     probability     mean    lower   upper  size pract_neg pract_equiv\n  &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 auc_1 vs au…       1      5.69e-2  0.0522  0.0617   0.01         0        0   \n2 auc_1 vs au…       1      5.63e-2  0.0514  0.0610   0.01         0        0   \n3 auc_2 vs au…       0.394 -6.41e-4 -0.00537 0.00403  0.01         0        1.00\n# ℹ 1 more variable: pract_pos &lt;dbl&gt;\n\n\nDirectional contrast (vs 0)\n\nset size = 0\n\n\nsummary(pp_contrasts, size = 0, prob = 0.95)\n\n# A tibble: 3 × 9\n  contrast     probability     mean    lower   upper  size pract_neg pract_equiv\n  &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 auc_1 vs au…       1      5.69e-2  0.0522  0.0617      0        NA          NA\n2 auc_1 vs au…       1      5.63e-2  0.0514  0.0610      0        NA          NA\n3 auc_2 vs au…       0.394 -6.41e-4 -0.00537 0.00403     0        NA          NA\n# ℹ 1 more variable: pract_pos &lt;dbl&gt;\n\n\nHere is the more “manual” method. Useful for understanding.\n\npp_contrasts |&gt; \n  filter(contrast == \"auc_1 vs. auc_2\") |&gt; \n  mutate(auc1_gt_auc2 = if_else(difference &gt; 0, 1, 0)) |&gt;\n  pull(auc1_gt_auc2) |&gt; \n  mean()\n\n[1] 1\n\npp_contrasts |&gt; \n  filter(contrast == \"auc_1 vs. auc_3\") |&gt; \n  mutate(auc1_gt_auc3 = if_else(difference &gt; 0, 1, 0)) |&gt;\n  pull(auc1_gt_auc3) |&gt; \n  mean()\n\n[1] 1\n\npp_contrasts |&gt; \n  filter(contrast == \"auc_2 vs. auc_3\") |&gt; \n  mutate(auc2_gt_auc3 = if_else(difference &gt; 0, 1, 0)) |&gt;\n  pull(auc2_gt_auc3) |&gt; \n  mean()\n\n[1] 0.394\n\n\nPlots\n\ntheme_set(theme_classic()) \npp_tidy %&gt;% \n  mutate(model = factor(model, levels = c(\"auc_1\", \"auc_2\", \"auc_3\"))) %&gt;%\n  ggplot() + \n  geom_histogram(aes(x = posterior, fill = model), color = \"black\", alpha = .4, \n                 bins = 30) +\n  facet_wrap(~model, ncol = 1) +\n  scale_y_continuous(\"Posterior Probability\", breaks = c(0, 500, 1000)) +\n  # ylab(\"Posterior Probability Density\") +\n  xlab(\"Area Under ROC Curve\")"
  },
  {
    "objectID": "bayes.html#directly-with-stan",
    "href": "bayes.html#directly-with-stan",
    "title": "2  Bayesian Analyses with rstanarm",
    "section": "2.4 Directly with STAN",
    "text": "2.4 Directly with STAN\nPivot data to long format\n\nauc_long &lt;- auc |&gt; \n  pivot_longer(\n    cols = starts_with(\"auc_\"),\n    names_to = \"model\",\n    values_to = \"auc\") |&gt; \n  rename(id = repeat_id,\n         id2 = fold_id) |&gt; \n  mutate(model_2 = if_else(model == \"auc_2\", 1, 0),\n         model_3 = if_else(model == \"auc_3\", 1, 0),\n         model = fct(model, levels = c(\"auc_1\", \"auc_2\", \"auc_3\")))\n\nauc_long |&gt; head()\n\n# A tibble: 6 × 6\n     id   id2 model   auc model_2 model_3\n  &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1     1 auc_1 0.908       0       0\n2     1     1 auc_2 0.841       1       0\n3     1     1 auc_3 0.844       0       1\n4     1     2 auc_1 0.897       0       0\n5     1     2 auc_2 0.851       1       0\n6     1     2 auc_3 0.853       0       1\n\n\nFix model directly with stan_glmer()\n\nset.seed(101)\npp2 &lt;- auc_long |&gt; \n  stan_glmer(data = _,\n             formula = auc ~ model_2 + model_3 + (1 | id2/id),\n         # prior_intercept = rstanarm::student_t(autoscale = TRUE),\n         # prior = rstanarm::student_t(autoscale = TRUE),\n         # hetero_var = TRUE,\n         # transform = tidyposterior::logit_trans,  # for skewed & bounded AUC\n         iter = 2000, chains = 4, # defaults listed here for easy increase  \n         adapt_delta = .80,   # default = .80.  Increase to &lt; 1\n         # cores = 4, seed = 12345,\n         family = gaussian, \n)  \n\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 3.2e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 5.171 seconds (Warm-up)\nChain 1:                0.339 seconds (Sampling)\nChain 1:                5.51 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.8e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 4.503 seconds (Warm-up)\nChain 2:                0.397 seconds (Sampling)\nChain 2:                4.9 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2.8e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 4.871 seconds (Warm-up)\nChain 3:                0.305 seconds (Sampling)\nChain 3:                5.176 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1.8e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 5.111 seconds (Warm-up)\nChain 4:                0.398 seconds (Sampling)\nChain 4:                5.509 seconds (Total)\nChain 4: \n\n\nMake new data for posterior prediction\n\nnew_dat2 &lt;- tibble(id = c(1,1,1), id2 = c(1,1,1), \n                   model_2 = c(0,1,0),\n                   model_3 = c(0,0,1))\n\nnew_dat2 |&gt; print(n = 3)\n\n# A tibble: 3 × 4\n     id   id2 model_2 model_3\n  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1     1       0       0\n2     1     1       1       0\n3     1     1       0       1\n\n\n\npp2_tidy &lt;- posterior_epred(pp2, newdata = new_dat2, seed = 123, re.form = NA) |&gt; \n  as_tibble()\nnames(pp2_tidy) &lt;- c(\"auc_1\", \"auc_2\", \"auc_3\") \n\npp2_tidy &lt;- pp2_tidy |&gt; \n pivot_longer(everything(), names_to = \"model\", values_to = \"posterior\")\n\nclass(pp2_tidy) &lt;- c(\"posterior\", class(pp2_tidy))\n\nCompare\n\npp_tidy |&gt; head()\n\n# Posterior samples of performance\n# A tibble: 6 × 2\n  model posterior\n  &lt;chr&gt;     &lt;dbl&gt;\n1 auc_1     0.903\n2 auc_2     0.845\n3 auc_3     0.849\n4 auc_1     0.903\n5 auc_2     0.849\n6 auc_3     0.846\n\npp2_tidy |&gt; head()\n\n# Posterior samples of performance\n# A tibble: 6 × 2\n  model posterior\n  &lt;chr&gt;     &lt;dbl&gt;\n1 auc_1     0.903\n2 auc_2     0.845\n3 auc_3     0.849\n4 auc_1     0.903\n5 auc_2     0.849\n6 auc_3     0.846"
  },
  {
    "objectID": "bayes.html#transformations",
    "href": "bayes.html#transformations",
    "title": "2  Bayesian Analyses with rstanarm",
    "section": "2.5 Transformations",
    "text": "2.5 Transformations\nCan use transformations in tidyposterior package\ntidyposterior::logit_trans is useful for auROC\n\napply transform to raw data (auROCs) - logit_trans$func()\nfit model\nget posterior\napply inverse transform to posterior - logit_trans$inv()"
  },
  {
    "objectID": "ancova_repeated_measures.html#overview",
    "href": "ancova_repeated_measures.html#overview",
    "title": "3  ANCOVA vs. Difference Scores",
    "section": "3.1 Overview",
    "text": "3.1 Overview\nThere are at least two obvious options for the analysis of a design that involved Group (e.g., intervention) x Time (pre-test vs. post-test) when participants are randomly assigned to Group and pre-test is measured before that random assignment (such that we can be certain the pre-test is not correlated with Group at the population level).1\n\nA traditional repeated measures analysis with Group as a between subject factor and Time (pre-test vs. post-test) as a within subject factor. In this analysis, we are interested in the Group X Time interaction. To accomplish this analysis within the GLM, we regress post-test vs. pre-test difference score on Group and test the parameter estimate for the Group effect. (see below)\nAn ANCOVA analysis with Group as a between subjects factor and pre-test scores as a covariate. Post-test scores are the dependent variable. To accomplish this analysis within the GLM, we regress post-test scores on Group and Pre-test scores and test the parameter estimate for the Group effect.\n\nAlthough it may not be immediately obvious, these two analyses are almost identical if we do some simple manipulation of the GLM models\nLets call pre-test scores \\(y_1\\) and post-test scores \\(y_2\\)\nFor the repeated measures analyses:\n\n\\((y_2 - y_1) = b_0 + b_1*Group\\), which can be re-written as\n\\(y_2 = b_0 + b_1*Group + y_1\\)\n\nFor ANCOVA analyses\n\n\\(y_2 = b_0 + b_1*Group + b_2*y_1\\)\n\nAs you can see, the two equations are almost equivalent. In both equations, our primary hypothesis requires a test of \\(b_1\\). The only difference across these two GLMS is that for ANCOVA, we estimate \\(b_2\\) (the coefficient for \\(y_1\\)) such that it minimizes the SSE whereas for the repeated measures approach we fix that coefficient to \\(1\\). It should be obvious that the ANCOVA will have an SSE that is lower than the repeated measures approach unless \\(b_2\\) = 1. \\(b_2\\) will only equal 1 if\n\nthe variances of \\(y_1\\) and \\(y_2\\) are equal,\n\\(y_1\\) and \\(y_2\\) are perfectly correlated, and\nThe magnitude of the Group effect is the same for all subjects\n\nThis will almost never be true. At a minimum, assuming we measure \\(y_1\\) and \\(y_2\\) with less than perfect reliability, they will not correlate perfectly.\nBecause the SSE will be lower for the ANCOVA approach, the standard error will be lower for the test of \\(b_1\\) and we will have more power to test if it is different from 0. ANCOVA is the preferred approach. 2"
  },
  {
    "objectID": "ancova_repeated_measures.html#simulation",
    "href": "ancova_repeated_measures.html#simulation",
    "title": "3  ANCOVA vs. Difference Scores",
    "section": "3.2 Simulation",
    "text": "3.2 Simulation\n\nlibrary(tidyverse)\n\nIt is trivial to simulate these two analyses to demonstrate the improvements in power offered by the ANCOVA approach.\nLets assume\n\nThe groups do not systematically differ on \\(y_1\\) (given random assignment. Of course, in any sample within the simulation there will be non-systematic differences across groups do to sampling error).\nThe groups differ by 1.5 units on \\(y_2\\) (approximately 1/2 of a standard deviation for a moderate effect size). We will fix this effect to be the same for all participants (if we allowed to vary, the power advantage for ANCOVA would increase further)\n\\(y_1\\) and \\(y_2\\) have equal variances (set to 10; if these variances were not equal, the power advantage will increase for ANCOVA). We will set the mean for \\(y\\), without intervention to 20. This has no effect on power.\n\\(y_1\\) and \\(y_2\\) are correlated at 0.75 (this value could be adjusted up and down. As it decreases, the power advantage will increase for ANCOVA. 0.75 is a high estimate in my experience for this correlation).\nWe will use a sample size of 50\n\nHere is a function to generate sample data that meet these assumptions\n\nsim_data &lt;- function(sim_num) {\n  n &lt;- 50\n  group_effect &lt;-1.5 \n  sigma &lt;- matrix(c(10, 7.5, 7.5, 10), nrow = 2)\n  means &lt;- c(20, 20)\n  \n  y &lt;- MASS::mvrnorm(n = n, mu = means, Sigma = sigma)\n  \n  tibble(sim_num = sim_num,\n         id = 1:n,\n         group = rep(c(\"control\", \"intervention\"), times = n/2),\n         y1 = y[,1],\n         y2 = if_else(group == \"intervention\", \n                      y[,2] + group_effect,\n                      y[,2]),\n         c_group = if_else(group == \"intervention\", 0.5, -0.5))\n}\n\nAnd a function to run the two analyses and extract \\(b_1\\) and its p-value\n\nget_results &lt;- function(d){\n  \n  m_rep &lt;- lm(y2 - y1 ~ c_group, data = d) |&gt; \n    broom::tidy() |&gt; \n    mutate(sim_num = d$sim_num[1],\n           method = \"repeated\")\n  \n  m_ancova &lt;- lm(y2 ~ c_group + y1, data = d) |&gt; \n    broom::tidy() |&gt; \n    mutate(sim_num = d$sim_num[1],\n           method = \"ancova\")\n  \n  bind_rows(m_rep, m_ancova)\n}\n\nNow lets run 5,000 simulations\n\nset.seed(123456)\n\nsims &lt;- 1:5000 |&gt; \n  map(\\(sim_num) sim_data(sim_num)) |&gt; \n  map(\\(d) get_results(d)) |&gt; \n  list_rbind()\n\nAnd check the results\n\nFirst confirm that both methods extract the correct parameter estimate of 5\n\n\nsims |&gt; \n  filter(term == \"c_group\") |&gt; \n  group_by(method) |&gt; \n  summarize(mean_b = mean(estimate))\n\n# A tibble: 2 × 2\n  method   mean_b\n  &lt;chr&gt;     &lt;dbl&gt;\n1 ancova     1.49\n2 repeated   1.49\n\n\n\nEvaluate power (percent sig effects for group)\n\n\nsims |&gt; \n  filter(term == \"c_group\") |&gt; \n  mutate(sig = if_else(p.value &lt; .05, 1,  0)) |&gt; \n  group_by(method) |&gt; \n  summarize(power = mean(sig))\n\n# A tibble: 2 × 2\n  method   power\n  &lt;chr&gt;    &lt;dbl&gt;\n1 ancova   0.683\n2 repeated 0.634\n\n\nUse ANCOVA not repeated measures unless you want to leave this power benefit on the table!"
  },
  {
    "objectID": "ancova_repeated_measures.html#footnotes",
    "href": "ancova_repeated_measures.html#footnotes",
    "title": "3  ANCOVA vs. Difference Scores",
    "section": "",
    "text": "Note that the test of the intercept in this GLM is equivalent to the test of the Time main effect. To get the Group main effect, we need to fit a second GLM, where the mean of pre-test and post-test is regressed on Group. But these effects are not typically our focus in this design.↩︎\nNote that this is only true if \\(y_1\\) is unrelated to Group as is true with random assignment to Group and pre-test measured before that assignment \\(y_2\\) could be expected to be correlated systematically across samples with Group, the test of \\(b_1\\) will be biased and this analysis approach should not be done. The repeated measures analyses is the appropriate analysis in that instance.↩︎"
  },
  {
    "objectID": "transformations.html#determine-optimal-range-for-lambda",
    "href": "transformations.html#determine-optimal-range-for-lambda",
    "title": "4  Transformations",
    "section": "4.1 Determine optimal range for lambda",
    "text": "4.1 Determine optimal range for lambda\nCalculate and display plot of lambda values\n\nscores &lt;- exp(rnorm(10))\nout &lt;- MASS::boxcox(lm(scores~1))\n\n\n\n\nView optimal lambda and CI values\n\nrange(out$x[out$y &gt; max(out$y)-qchisq(0.95,1)/2])\n\n[1] -0.2626263  1.4343434\n\nout$x[which.max(out$y)]\n\n[1] 0.5050505"
  },
  {
    "objectID": "transformations.html#applying-transformation",
    "href": "transformations.html#applying-transformation",
    "title": "4  Transformations",
    "section": "4.2 Applying transformation",
    "text": "4.2 Applying transformation\nsee help for car::bcPower()\n\nU &lt;- c(NA, (-3:3))\n\n## Not run: bcPower(U, 0)  # produces an error as U has negative values\ncar::bcPower(U, lambda = 0, gamma = 4)\n\n          Z1^0\n[1,]        NA\n[2,] 0.0000000\n[3,] 0.6931472\n[4,] 1.0986123\n[5,] 1.3862944\n[6,] 1.6094379\n[7,] 1.7917595\n[8,] 1.9459101\n\ncar::bcnPower(U, lambda = 0, gamma = 2)\n\n[1]         NA -1.1947632 -0.8813736 -0.4812118  0.0000000  0.4812118  0.8813736\n[8]  1.1947632\n\ncar::basicPower(U, lambda = 0, gamma = 4)\n\n       log(Z1)\n[1,]        NA\n[2,] 0.0000000\n[3,] 0.6931472\n[4,] 1.0986123\n[5,] 1.3862944\n[6,] 1.6094379\n[7,] 1.7917595\n[8,] 1.9459101\n\ncar::yjPower(U, lambda = 0)\n\n[1]         NA -7.5000000 -4.0000000 -1.5000000  0.0000000  0.6931472  1.0986123\n[8]  1.3862944"
  }
]