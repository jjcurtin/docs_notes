---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Analysis of Repeated Measures in R

This is a long exploration of how to handle repeated measures in R.  It focused primarily on `lm()` vs `lmer()` but also considers `aov_car()` from the afex package.  It is limited to considering a single within subject variable with 2 or 3 levels but the conclusions generalize to models that also include between subject factors.

Conclusions:

* I prefer simple `lm()` with difference scores for 2 and 3 level time variable if I don't need/want to test main effect (2df) of time (which is suspect anyway) and I do want 1df time contrasts.  [If I really need the main effect test, use `aov_car()`].  

* HOWEVER, `aov_car()` should be considered.  It gives same 1df contrasts  (using `emmeans` package).  It does give main effect of time with corrections for violations if desired and it allows you to keep data in long format!  Not sure (not tested) if it could handle quantitiave between subject factors like lm() can.

`lmer()` with time as quantitative variable is preferred if I can focus on only the linear effect (assuming 3 levels) and particularly if I have missing data or timepoints that vary by participant.  If I had more time points and could also get quad, this might be better than lm() too because simpler than the many contrast possible with 4 levels of time.

If I had psuedoreplications on time, I would prefer the `lmer()` approach with categorical time because we could then model the by subject random slope for time and not worry about the sphericity assumption and stay in long format, etc.  If more levels (than 3) for time, I'd switch to lmer() with random slopes and quantitative time

## Set up

### Load packages and data

```{r}
#| message: false
#| warning: false

library(tidyverse)
library(lme4)
```

### Read and format data in long format
```{r}
d_long <- read_csv("repeated_measures.csv", col_types = cols()) |> 
  filter(dyad == "Patient") |> 
  select(-dyad) |> 
  filter(time > 0) |> 
  glimpse()

d_long |> print(n = 10)
```


### Format data in wide format
```{r}
d_wide <- d_long |> 
  select(study_id, arm, time, hdd) |> 
  pivot_wider(names_from = time, values_from = hdd) |> 
  rename(time1 = `1`,
         time2 = `2`, 
         time3 = `3`) |> 
  glimpse()

d_wide |> print(n = 10)
```

### Setting contrast matrices for factors

* see: https://marissabarlaz.github.io/portfolio/contrastcoding/
* Default for unordered factors is treatment/dummy
* We typically want centered orthogonal, and unit weighted.  Helmert often good choice
* Below, we demo how to set up contrast matrices by code
* We will apply them later as needed
* We make Helmert contrast matrices for 2 and 3 level factors here
```{r}
(helmert2 = matrix(c(-.5, .5), ncol = 1, dimnames = list(c("time1", "time2"), c("t2v1"))))
(helmert3 = matrix(c(-2/3, 1/3, 1/3, 0, -.5, .5), ncol = 2, dimnames = list(c("time1", "time2", "time3"), c("t32v1", "t3v2"))))
```


## Explore two level repeated measures 

* Use only time 1 and time 2 to demo two level repeated measures analyses

```{r}
d2_long <- d_long |> 
  filter(time < 3) |> 
  glimpse()

d2_wide <- d_wide |> 
  select(-time3) |> 
  glimpse()
```

### diff score approach

This is the standard/traditional way to analyse this design and the benchmark for comparison

* Time effect tested using difference score for time2 - time1
* Explicitly calculate that difference score in df
* No assumption of sphericity is needed

This is the test of the two level Time variable
```{r}

d_wide |> 
  mutate(diff = time2 - time1) |> 
  lm(diff ~ 1, data = _) |> 
  summary()
```

If you wanted to test the intercept in the between subject model you could do this.  Not really useful here, but can be informative in some situations and also used when we have between subject variables in the design.
```{r}
d_wide |> 
  mutate(ave = (time2 + time1) / 2) |> 
  lm(ave ~ 1, data = _) |> 
  summary()
```

### lmer approach with time as manually coded regressor

* This is first option using manually coded regressor for time (time_2v1, 0.5 vs. -0.5)
* Use random intercept but no random slope for time when there are no [psuedoreplications](https://psyteachr.github.io/stat-models-v1/linear-mixed-effects-models-with-one-random-factor.html) (i.e., where there is only one observation per cell).  It is not possible to calculate both a by-subject random slope AND a by-subject random intercept for Time for each subject when there are only two observations for Time (i.e., this "two parameter" model would perfectly fit the two observations available for each subject!)
* Use `Anova()` from car package on lmer object to get p-values


First code the regressor for the time contrast
```{r}
d2_long <- d2_long |> 
  mutate(time_2v1 = if_else(time == 1, -.5, .5)) |>
  glimpse()

d2_long |> print(n = 10)
```

Then do analysis. 

* Do NOT use by subject random slope for time as noted above
* Both parameter estimates (time and intercept) match above
* p value for time and intercept match traditional diff score analysis

```{r}
m2a <- d2_long |> 
  lmer(hdd ~ time_2v1 + (1 | study_id), data = _)

m2a

m2a |> 
  car::Anova(type = 3, test = "F")
```

### lmer approach with time as factor

* Code time as a factor

```{r}
d2_long <- d2_long |> 
  mutate(time = factor(time, labels = c("time1", "time2")))
```

* Default contrasts for Time were treatment/dummy
* We will apply centered (helmert) contrast matrix from earlier
```{r}
contrasts(d2_long$time)
contrasts(d2_long$time) <- helmert2
contrasts(d2_long$time)
```

* Do NOT use by subject random slope for time as described earlier
* Paremeter estimates and p-values match
```{r}
m2b <- d2_long |> 
  lmer(hdd ~ time + (1 | study_id), data = _)

m2b

m2b |> 
  car::Anova(type = 3, test = "F")
```

### lmer approach with by-subject random effect of time

* NOPE!
* ! number of observations (=66) <= number of random effects (=66) for term (1 + c_time | study_id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable
* This WOULD be correct if we had psudeoreplications
* This is because you cant estimate both a random intercept and a random slope for time with only two observations.  The analogy would be fitting a two parameter model when N=2.  Model would perfectly fit the data!
* This is true regardless if you use time as factor or regressor.  Those are equivalent analyses.
```{r}
#| eval: false

d2_long |> 
  lmer(hdd ~ time + (1 + time | study_id), data = _) |> 
  car::Anova(type = 3, test = "F")
```

You could try to force it

* ignore check of nobs vs nRe
* In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :Model is nearly unidentifiable: large eigenvalue ratio - Rescale variables?
* It does yield the same solution as earlier models but with the above warning
```{r}
#| eval: false

m2c <- d2_long |> 
  lmer(hdd ~ time + (1 + time | study_id), data = _,
       control = lmerControl(check.nobs.vs.nRE = "ignore"))

m2c

m2c |> 
  car::Anova(type = 3, test = "F")
```

## Explore three level repeated measures 

### Using `afex::aov_car`

`aov_car()` from afex supports traditional anova designs in R.  see also `aov()`

* Remember that with 3 level repeated measures variables we now need to make an assumption of sphericity
* This means that the variance of all the difference scores (e.g. time1 - time2, time1-time3, time2-time3) are equal
* This assumption is similar to the assumption about equal variances across groups in between subject anovas. These assumptiosn allow each model to pool variances across groups (between subjects) or difference scores (within subject) to test the omnibus (in this case 2df) main effect.   Remember that the error term for a 1 df within subject test is the variance of the difference.  For 2df test, we need to pool two of these differences, which is only appropriate if those variances are the same.
* Compound symetry is a stricter form of sphericity (var1 + var2 + covar12 = k for all combos of variates) but its often needed to have sphericity assumption met.
* Machley test for sphericity exists but it is a poor test.  Underpowered for small N, overpowered for large N.
* If sphericity is violated, you can do df correction (GG or HF)


First we need to set up 3-level time as a factor with helmert contrasts using the long format data

```{r}
d_long <- d_long |> 
  mutate(time = factor(time, labels = c("time1", "time2", "time3")))

contrasts(d_long$time)
contrasts(d_long$time) <- helmert3
contrasts(d_long$time)
```

`aov_car()` provides us with main effect of Time (2 df) with the pooled error term (64 ddf). 

* As noted above, this is only appropriate if sphericity assumption is met.  

```{r}
m_afex <- d_long |> 
  afex::aov_car(hdd ~ time + Error(study_id/time), data = _)

summary(m_afex)
```

* Can get corrections to dfs if assumption is violated.  Use `anova()` from stats package

```{r}
anova(m_afex, correction = "none")
anova(m_afex, correction = "GG")
anova(m_afex, correction = "HF")
```

We can use `emmeans` package to get cell means and 1 df contrasts

* note the formula for the mean contrasts it NOT the helmert coefficients, but the actual algebraic formula for the contrasts we want.
* This ALSO gives use tests of contrasts with SEPARATE, not POOLED error (note ddf = 32)
* We want separate error because no assumption of sphericity needed
* I have not seen pooled contrasts reported though they make sense to me as an option IF pooling is appropriate given sphericity
```{r}
(means <- emmeans::emmeans(m_afex, ~ time))
emmeans::contrast(means, list(t32v1 = c(-1, .5, .5), t3v2 = c(0,-1,1))) 
```


### Diff score approach

First here are the time contrast models.  

* CRITICALLY, this tests contrasts with SEPARATE (rather than pooled) error.  Note ddf = 32 for contrasts
* This matches contrasts from `aov_car()`
* This method does not provide test of main effect of time (2 df)

```{r}
d_wide |> 
  mutate(diff_23v1 = (time2 + time3) / 2 - time1) |> 
  lm(diff_23v1 ~ 1, data = _) |> 
  summary()

d_wide |>
  mutate(diff_3v2 = time3 - time2) |> 
  lm(diff_3v2 ~ 1, data = _) |> 
  summary()
```


And here is the main effects model for the intercept for time

```{r}
d_wide |> 
  mutate(ave = (time1 + time2 + time3) / 3) |> 
  lm(ave ~ 1, data = _) |> 
  summary()
```


### lmer approach with time as factor

* We do NOT include by subject random slope for time because there are no pseudoreplications.  Once again, estimating 3 parameters (random intercept and two random slopes) will perfectly fit the 3 observations per subject
* Gets 2df main effect but NOT contrasts
* Matches main effect results from `aov_car()` when sphericity is assumed.
* This makes some sense too.  If you dont allow for random slopes, then all the subjects have the SAME difference scores for the two contrasts and therefore 0 variance.   Thus the variance of both are the same and we are just left with variance in intercept and residual within subject.
* This solution is not appropriate if sphericity is not met
* And you would need to got to `aov_car()` or similar to test for sphericity and get corrections if needed.  NOT A GOOD SOLUTION IMHO
```{r}
m3a<- d_long |> 
  lmer(hdd ~ time + (1 | study_id), data = _)

m3a

m3a |> car::Anova(type = 3, test = "F")
```


### lmer approach with regressors for time

* Do NOT include by subject random slope for time because no pseudoreplications
* Gets 1 df contrasts for time and parameter estimates match
* BUT uses a pooled error to test contrasts. ddf = 64.  So p-values do NOT match.  Appropriate (better?) if sphericity holds but definitely not if it doesn't!
* Does not get main effect (2df) for time


First, add regressors for helmert contrasts for three level time variable
```{r}
d_long <- d_long |> 
  mutate(time_32v1 = case_match(time,
                                "time1" ~ -2/3,
                                c("time2", "time3") ~ 1/3),
         time_3v2 = case_match(time, 
                               "time1" ~ 0,
                               "time2" ~ -.5,
                               "time3" ~ .5))

d_long |> print(n = 10)
```


```{r}
m3b <- d_long |> 
  lme4::lmer(hdd ~ time_32v1 + time_3v2 + (1 | study_id), data = _)

m3b

m3b |> 
  car::Anova(type = 3, test = "F")
```

### lmer approach with regressors for time AND separate error terms

I don't show code for this but we could aggregate down to long format but just the two levels (with two rows per subject) of time separately for each time contrast and then we would be back to the 2 level lmer approach to time from above.  This would be fine but its cumbersome so I don't think this is worth it.


### With random effect for time

* NOPE
* ! number of observations (=99) <= number of random effects (=99) for term (1 + time | study_id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable
* Again, no pseudoreplications so no by-subject random effect for time can be estimated 
```{r}
#| eval: false

m3c <- d_long |> 
  lmer(hdd ~ time + (1 + time | study_id), data = _)
```

And if we force it, we get warnings...
* 1: In checkConv(attr(opt, "derivs"), opt\$par, ctrl = control$checkConv,  :
  unable to evaluate scaled gradient
* In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues

```{r}
#| eval: false

m3c <- d_long |> 
  lmer(hdd ~ time + (1 + time | study_id), data = _,
       control = lmerControl(check.nobs.vs.nRE = "ignore",
                             optCtrl = list(maxfun = 1000000)))
```

### lmer with time as continuous variable

Now we can specify by subject random slope for time

And this model doesn't make sphericity assumption because it allows for the slopes to vary by subject

```{r}
d_long <- d_long |> 
  mutate(r_time = as.numeric(time) * 2,  # for 2, 4, and 6 months
         c_time = r_time - 2) |> 
  glimpse()
```

```{r}
m_raw <- d_long |> 
  lmer(hdd ~ r_time + (1 + r_time | study_id), data = _)

m_raw

m_raw |> 
  car::Anova(type = 3, test = "F")
```

Centering matters - here only for intercept but more impacts with higher order models
```{r}
m_center <- d_long |> 
  lmer(hdd ~ c_time + (1 + c_time | study_id), data = _)

m_center

m_center |> 
  car::Anova(type = 3, test = "F")
```

To fit poly model, you probably want to use centered time because linear effect will be at time = 0 (time mid point).  Or chose another sensible 0 point.

```{r}
d_long <- d_long |> 
  mutate(c_time2 = c_time^2) |> 
  glimpse()
```

But you can't fit poly model with quadratic effect with random slopes because, once again cant estimate intercept and both random slopes without more observations per subject
 
Error: number of observations (=99) <= number of random effects (=99) for term (1 + c_time + c_time2 | study_id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable
```{r}
#| eval: false
m_poly <- d_long |> 
  lmer(hdd ~ c_time + c_time2 + (1 + c_time + c_time2 | study_id), data = _)
```
 
But you CAN return to not estimating by subject random slopes.  I suspect that this has the same sphericity issue though!  Not sure about that but it seems to make sense that you are putting an unrealisitc (or at least unevaluated) assumption on the strucure of the error.
```{r}
m_poly <- d_long |> 
  lmer(hdd ~ c_time + c_time2 + (1 | study_id), data = _)

m_poly

m_poly |> 
  car::Anova(type = 3, test = "F")
```

# Predicted values and figures

This is a demo of predicted values and plot for the model with time as a continuous variable.  I use the linear model of time and raw time scores.   For the plot, centering doesn't matter.  Its all the same model space and it easier to understand in raw time units.  Alternatively, we could use centered time and then change the values on the axis that displays time.
```{r}
# we can add the means from raw data to plot and then superimpose the fitted model
d_plot <- d_long |> 
  group_by(r_time) |> 
  summarize(hdd_mean = mean(hdd), hdd_se = sd(hdd)/ sqrt(length(hdd)))

d_plot <- d_plot |> 
  mutate(hdd_pred = predict(m_raw, newdata = d_plot, re.form = NA)) |> 
  glimpse()

d_plot |> 
  ggplot(aes(x = r_time)) +
    geom_errorbar(aes(ymin = hdd_mean - hdd_se, ymax = hdd_mean + hdd_se),
                  width = .25) +
    geom_point(aes(y = hdd_mean)) +
    geom_line(aes(y = hdd_pred), color = "red", linewidth = 1.5) +
    ylim(0, 50)
```